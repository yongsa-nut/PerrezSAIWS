{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pD4ob-YjNk8i"
      },
      "outputs": [],
      "source": [
        "openai_key = \"\" ## Please change it to your key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U_mOzmVuNs_y"
      },
      "outputs": [],
      "source": [
        "## Comment this out if you run on colab\n",
        "##!pip install openai \n",
        "##!pip install backoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GxV42TtZNy45"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import backoff\n",
        "\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEQbs7WjN5Hr",
        "outputId": "c94acdb4-a5a2-48b1-c536-c333f9466826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Hello! It's nice to meet you. How can I help you?\"]\n",
            "['Hello! How can I assist you today?']\n",
            "['Hello! How can I help you today? If you have any questions or need assistance, feel free to ask.']\n"
          ]
        }
      ],
      "source": [
        "## We don't need to maintain message history for chat mode since \n",
        "## we will concat the prompts if history is true.\n",
        "## Also no system message to make it comparable to text-davinci-003\n",
        "## We test the snapshot so that the results are reproducible.\n",
        "## The model are \"text-davinci-003\", \"gpt-3.5-turbo\", \"gpt-4\"\n",
        "models = [\"text-davinci-003\", \"gpt-3.5-turbo\", \"gpt-4\"]\n",
        "\n",
        "## Backofff for chat since both chatgpt and gpt-4 are always heavy used.\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=6000)\n",
        "def completions_with_backoff(**kwargs):\n",
        "    return openai.Completion.create(**kwargs)\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=6000)\n",
        "def chat_completions_with_backoff(**kwargs):\n",
        "    return openai.ChatCompletion.create(**kwargs)\n",
        "\n",
        "def gptQuery(prompt, model, temperature = 0, n=1, logprobs=1, echo = False, **kwargs):\n",
        "  if model == models[0]:\n",
        "    out=completions_with_backoff(model=model, \n",
        "                               prompt=prompt, \n",
        "                               logprobs=logprobs, \n",
        "                               temperature=temperature, max_tokens = 2048,\n",
        "                               n = n, **kwargs)\n",
        "    # out=openai.Completion.create(model=model, \n",
        "    #                            prompt=prompt, \n",
        "    #                            logprobs=logprobs, \n",
        "    #                            temperature=temperature, max_tokens = 2048,\n",
        "    #                            n = n, **kwargs)\n",
        "    if echo: print(out)\n",
        "    return [response.text.strip() for response in out.choices ]\n",
        "  if model == models[1] or model == models[2]:\n",
        "    out = chat_completions_with_backoff(model=model,\n",
        "                                     messages=[{\"role\":\"user\",\"content\":prompt}], \n",
        "                                     temperature=temperature, max_tokens = 2048,\n",
        "                                     n=n)\n",
        "    # out = openai.ChatCompletion.create(model=model,\n",
        "    #                                  messages=[{\"role\":\"user\",\"content\":prompt}], \n",
        "    #                                  temperature=temperature, max_tokens = 2048,\n",
        "    #                                  n=n, **kwargs)\n",
        "    if echo: print(out) \n",
        "    return [response.message.content.strip() for response in out.choices ]\n",
        "\n",
        "## Test that the openAIkey is working correctly\n",
        "print(gptQuery(prompt = \"Hello Test Test\", model=models[0]))\n",
        "print(gptQuery(prompt = \"Hello Test Test\", model=models[1]))\n",
        "print(gptQuery(prompt = \"Hello Test Test\", model=models[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEfSQuSOqND"
      },
      "source": [
        "#Declaring Perrez Story\n",
        "\n",
        "The stories below are from the Stress and Coping Process Questionnaire (SCPQ) from the Stress, coping, and health: A situation-behavior approach: Theroy, methods, and applications book by Perrez and Reicherts 1992.\n",
        "\n",
        "Each story consists of three phases: Onset, Continuation, and Outcome.\n",
        "The order is the same as the original study.\n",
        "\n",
        "The story can be classifed into two type: Aversive and Lose & Failure. \n",
        "\n",
        " - Aversive: 1, 3, 6, 8, 9, 10, 12, 14, 16.\n",
        " - Loss & Failure: 2, 4, 5, 7, 8, 11, 13 ,17, 18.\n",
        "\n",
        "Aversive stories can be breakdown into two domains:\n",
        "- Social:\n",
        "  - Source: close, acquainted, strange persons\n",
        "- Professional: \n",
        "  - Source: work activity, equal, superior persons\n",
        "\n",
        "Loss and Failure can be breakdown into two domains:\n",
        "- Social:\n",
        "  - Sources: persons, activities/projects, objects\n",
        "- Professional:\n",
        "  - Sources: persons, activities/projects, objects\n",
        "\n",
        "The story have two possible outcomes: Positive or Negative.\n",
        "\n",
        " - Positive: 1, 3, 4, 5, 8, 11, 14, 17, 18\n",
        " - Negative: 2, 6, 7, 9, 10, 12, 13, 15, 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SBb_Co0ZOpbE"
      },
      "outputs": [],
      "source": [
        "## Need to adjust for indexing starting at 0\n",
        "AVERSIVE = \"aversive\"\n",
        "LOSSFAILURE = \"lossfailure\"\n",
        "\n",
        "aversive_stories = [1,3,6,8,9,10,12,14,16] \n",
        "lossfailure_stories = [2,4,5,7,8,11,13,17,18]\n",
        "\n",
        "types = [ AVERSIVE if i in aversive_stories else LOSSFAILURE for i in range(1,19)]\n",
        "\n",
        "\n",
        "pos = [1,3,5,8,11,14,17,18]\n",
        "neg = [2,6,7,9,10,12,13,15,16]\n",
        "\n",
        "## Aversive: Critism from the partner\n",
        "story1 = [\"You have forgotten to do something important for your partner. You become aware of it just at the moment when your partner asks about it. Your partner gets very angry and blames you.\",\n",
        "          \"After a while, your partner’s attitude to you has hardly changed: he/she is still angry, and he still blames you for your mistake.\",\n",
        "          \"At least your partner has apologized for having been so vehement. You work together to try and find a way to repair the damage.\"]\n",
        "\n",
        "## Loss&Failure: Loss of a friendly relationship\n",
        "story2 = [\"A person who was very close to you, especially in recent times, has to move away unexpectedly. When you parted, you reassured each other you would both keep in close contact. But his/her new home is quite far away. You could see each other only rarely, if at all.\", \n",
        "          \"In the meantime, some weeks have passed. The person hasn’t gotten in touch with you again. Nevertheless, you feel from time to time that you miss him/her.\",\n",
        "          \"Finally, it has become clear that your friendship is not the same anymore. Your relationship with other people can’t replace what you have lost. Now and then, you feel disappointed about the relationship you have lost.\"]\n",
        "\n",
        "## Aversive: Reproaches from colleagues about professional commitment\n",
        "story3 = [\"You are together with some colleagues. One says that you don't pull your weight when there is difficult work. He claims that you don't think of other colleagues.\", \n",
        "          \"Sometime later, another colleague hints that the problem is not that you don’t think of others but that you lack any real interest in the work.\",\n",
        "          \"Finally, you realize what your colleagues were really getting at, and you, for your part, were able to convince them that you sometimes are more cautious at your work than others.\"]\n",
        "\n",
        "## Lose&Failure: Loss of a percious object\n",
        "story4 = [\"You cannot find something which is very precious to you. It is associated with the memory of someone who is/was important to you. You have to face up to the possibility that you have lost it.\", \n",
        "          \"Meanwhile, the time has passed. The missing object, which is so important to you did not appear again.\",\n",
        "          \"The object seems to definitely be lost. However, you manage to accept this by thinking of other things and memories which are just as precious to you.\"]\n",
        "\n",
        "## Lose&Failure: Lose of a project\n",
        "story5 = [\"You have invested a lot of time and effort in your work project. It is really important for you that you finish this project in a few days and that it is done well. Then you realize that important material is not available. It is vital you have it in order to finish the work.\", \n",
        "          \"Shortly before the deadline, you realize that you have not found a way to get the material you need so badly.\",\n",
        "          \"In the end, you concentrated more on other aspects of your task and did a successful job of it. You finally finished the project late, but you did your work well.\"]\n",
        "\n",
        "## Aversive: critism from acquinted persons\n",
        "story6 = [\"You are with others, friends, and some people you don’t know. You have just done something embarrassing. Somebody has noticed it and brought it to the attention of others. All around, people are laughing at you. You can also hear some impertinent remarks.\", \n",
        "          \"Sometime later, people hadn't yet calmed. They are still making sarcastic remarks about your predicament and are still laughing about it.\",\n",
        "          \"People still hadn't calmed down when you left. They were still being cheeky and belittling regarding your mistake.\"]\n",
        "\n",
        "## Lose&Failure: Loss of activities/projects \n",
        "story7 = [\"Your workplace will soon be reorganized. When it happens, you should finish one aspect of the work you have been doing until now. It is work that is very familiar to you and that you have mastered. In its place, you will have to take on other tasks that are as yet undefined and probably not so easy for you. You will miss your previous work very much.\", \n",
        "          \"After a trial period, the new setup becomes definite. Your workplace is to be reorganized. The new tasks you have taken over are rather difficult and don't satisfy you. You're really missing your previous work.\",\n",
        "          \"You didn't get on very well with your new work. You miss your previous work very much. Other aspects of your work don’t compensate for this.\"]\n",
        "\n",
        "## Aversive: Critisim by a stranger  \n",
        "story8 = [\"Walking down a crowded street, you strike a parked car with your bag. The driver, who was just about to get in, inspects his car. He becomes very angry and blames you for having scratched the car. He becomes abusive towards you and wants you to pay for the damage.\", \n",
        "          \"The driver continues to be very angry. Again he loudly demands that you should pay for the damage.\",\n",
        "          \"The driver remained fairly angry. But finally, he seemed to accept that the scratches on his car were hardly likely to have been made by your bag.\"]\n",
        "\n",
        "## Aversive: Being charged with a difficult job by the boss \n",
        "story9 = [\"Previous relations with your boss have been quite complicated. Now your boss gives you a task which you are supposed to work on for the next two days. This job is very inconvenient for you because you have a lot of routine work to do at the moment.\", \n",
        "          \"Your boss tells you that your routine work also has to be done. As you begin to work on the new task, it becomes evident how difficult and time-consuming it really is. It seems that you will only finish it if you ignore your other work, and even then, you may have to work overtime on it.\",\n",
        "          \"You didn’t carry out the job in the assigned time. Also, a lot of routine work remained unfinished.\"]\n",
        "\n",
        "## Aversive: argument about problems in a relationship\n",
        "story10 = [\"You have just got to know someone you find pretty sympathetic. You have met several times and got on well together. Now you are talking about something which is important to you. The other person does not agree at all and says that your ideas and arguments seem “rather strange” to her.\", \n",
        "          \"Later the person says that she really goes to great lengths to understand you, but she does not manage to agree with you. Obviously, you could talk about this for a long time, she says, but maybe both of you see the world differently.\",\n",
        "          \"The disagreements between you remained until the end of the meeting. It was never clear to you what the disagreement was actually about.\"]\n",
        "\n",
        "## Lose&Failure: Lose of an interesting side job\n",
        "story11 = [\"Your firm recently advertised a very interesting job. You have the impression that you would be a possible candidate with your professional qualifications. For different reasons, you are hesitating to apply, although a fast decision is needed. Now you hear that one of your colleagues has applied for this job. He is qualified for this job, but you don’t like him.\", \n",
        "          \"Some days later, you hear that your colleague will probably get the job. It seems that he only has to accept the offer.\",\n",
        "          \"Your colleague has got the job. Meanwhile, you have concentrated successfully on the other tasks. You have already heard that soon new professional opportunities will be offered which may be of interest to you.\"]\n",
        "\n",
        "## Aversive: Reproaches from your partner\n",
        "story12 = [\"You and your partner have been having a difficult time together over the past few weeks. On several occasions, you could have criticized your partner without saying something. Now she/he is saying that she/he finds you “very disagreeable” at present.\", \n",
        "          \"Later, your partner repeats her/his vague reproach. You have only a vague idea as to the background of her/his remark. Your partner seems to be avoiding giving you an explanation.\",\n",
        "          \"It remains unclear what your partner means by her/his vague reproaches. You can only guess the reasons. The mutual reproaches are continuing.\"]\n",
        "\n",
        "## Lose&Failure: Lose of an important object\n",
        "story13 = [\"You are unable to find an important document that details your professional qualification. You need it urgently.\", \n",
        "          \"After a few days, the missing document still hasn’t appeared. It is highly important you should always have this document at your disposal.\",\n",
        "          \"You could not find the certificate in time. You had to show your credentials in another, less satisfactory way.\"]\n",
        "\n",
        "## Aversive: Being ignore by your colleagues\n",
        "story14 = [\"Your work colleagues are discussing a professional question in your presence. Although the topic concerns your job and you are familiar with the matter, they don’t attach any importance to your opinion. You have just given your opinion, but your colleagues don’t take notice of what you have said.\", \n",
        "          \"The discussion is continuing. Your colleagues still disregard your opinion.\",\n",
        "          \"Finally, you have succeeded in making your opinion known. Some of your colleagues have fully accepted your arguments.\"]\n",
        "\n",
        "## Lose&Failure: Lose of an object\n",
        "story15 = [\"You don’t have a good relationship with your landlord. Now he tells you that he is considering canceling your lease. Probably he will need your home for his own use. You are used to the flat, and you like the place and its location.\", \n",
        "          \"Not far from the prescribed cancelation time, your landlord tells you that he is probably going to cancel the lease and use the flat himself.\",\n",
        "          \"You have now to move out, and you could not find a similar flat in the vicinity.\"]\n",
        "\n",
        "## Aversive: Critisim from a colleague\n",
        "story16 = [\"You have a problem at work. A new colleague that you don’t know well yet is passing and is having a look at your work. Without being unfriendly, he implies that your work could be done in another, more efficient way.\", \n",
        "          \"The new colleague is explaining in a challenging way how the work can be done differently. It is not clear to you what he means. He then adds there may be different ways to solve the problem, but he stresses his “own experiences in the area.\",\n",
        "          \"It remains unclear to you if your colleague’s suggestion is valuable or not. His provocative behavior also seems ambiguous to you.\"]\n",
        "\n",
        "## Lose&Failure: Failure of a weekend arrangment\n",
        "story17 = [\"You are planning a journey. You intend to visit good friends who live far away. You have not met for a long time, and you have invested a lot of time and energy to ensure the trip came about. Now you receive the message that your visit has possibly to be canceled because of an illness in your friends’ family.\", \n",
        "          \"The day before your departure, you receive a message from your friends that it would probably be better to postpone your visit because of an illness in their family. If you postpone the journey, it will be for an indefinite time.\",\n",
        "          \"Finally, you could not visit your friends. You have changed your program, and you have fixed with your friends a new date for a visit.\"]\n",
        "\n",
        "## Lose&Failure: Loss of a cooperative work relationship (a colleague leaves)\n",
        "story18 = [\"A work colleague has recently left your firm. His departure surprised you. You worked well with him, and you have received a lot of professional support from him. When he was leaving, you both agreed to remain in contact and continue the professional exchange.\", \n",
        "          \"Meanwhile, the time has passed. After only one spontaneous contact by phone, you have never heard anything from him. Nevertheless, you continue to feel that you are missing his cooperation and support.\",\n",
        "          \"The professional exchange is indeed not the same as in former times, but from time to time, you continue to have contact with your colleague, and you meet occasionally. You have also begun to cooperate with other colleagues at the firm, and you receive a lot of professional support from them.\"]\n",
        "\n",
        "perrez_stories = [story1, story2, story3, story4, story5, story6, story7, story8,\n",
        "                  story9, story10, story11, story12, story13, story14, story15,\n",
        "                  story16, story17, story18]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUnYdyMwQLBR"
      },
      "source": [
        "#Declaring Perrez Questionnaire\n",
        "There are 6 sets of questions in total: 3 for each time and 2 for each type.  The questionnair is slightly modified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FJU5Wq6SQKMG"
      },
      "outputs": [],
      "source": [
        "## Lists of questions (maybe dict is better.)\n",
        "\n",
        "p1_aversive = []\n",
        "p2_aversive = []\n",
        "p3_aversive = []\n",
        "\n",
        "p1_lossfailure = []\n",
        "p2_lossfailure = []\n",
        "p3_lossfailure = []\n",
        "\n",
        "## Both types share the same measurments for all questions\n",
        "### We can just concat the answers to the question but doing this makes it easier to exclude answers later\n",
        "p1_measurement = []\n",
        "p2_measurement = []\n",
        "p3_measurement = []\n",
        "\n",
        "p1_Qnames = []\n",
        "p2_Qnames = []\n",
        "p3_Qnames = []\n",
        "\n",
        "## Emotion Questions\n",
        "### Emotion questions are always the same across types and times.\n",
        "### Q 1- 3\n",
        "\n",
        "eq_nervous = r\"\"\"Q. In this situation, I feel:\"\"\"\n",
        "eq_nervous_meas = r\"\"\"\n",
        "  0 very nervous/anxious\n",
        "  1 fairly nervous/anxious\n",
        "  2 somewhat nervous/anxious\n",
        "  3 somewhat calm/composed\n",
        "  4 fairly calm/composed\n",
        "  5 very calm/composed\n",
        "\"\"\"\n",
        "\n",
        "eq_depress = r\"\"\"Q. In this situation, I feel:\"\"\"\n",
        "eq_depress_meas = r\"\"\"\n",
        "  0 very depressed/sad\n",
        "  1 fairly depressed/sad\n",
        "  2 somewhat depressed/sad\n",
        "  3 somewhat cheerful/serene\n",
        "  4 fairly cheerful/serene\n",
        "  5 very cheerful/serene\n",
        "\"\"\"\n",
        "\n",
        "eq_angry = r\"\"\"Q. In this situation, I feel:\"\"\"\n",
        "eq_angry_meas = r\"\"\"\n",
        "  0 very angry/furious\n",
        "  1 fairly angry/furious\n",
        "  2 somewhat angry/furious\n",
        "  3 somewhat gentle/peaceful\n",
        "  4 fairly gentle/peaceful\n",
        "  5 very gentle/peaceful\n",
        "\"\"\"\n",
        "\n",
        "p1_aversive.extend([eq_nervous,eq_depress,eq_angry])\n",
        "p2_aversive.extend([eq_nervous,eq_depress,eq_angry])\n",
        "p3_aversive.extend([eq_nervous,eq_depress,eq_angry])\n",
        "p1_lossfailure.extend([eq_nervous,eq_depress,eq_angry])\n",
        "p2_lossfailure.extend([eq_nervous,eq_depress,eq_angry])\n",
        "p3_lossfailure.extend([eq_nervous,eq_depress,eq_angry])\n",
        "\n",
        "p1_measurement.extend([eq_nervous_meas,eq_depress_meas,eq_angry_meas])\n",
        "p2_measurement.extend([eq_nervous_meas,eq_depress_meas,eq_angry_meas])\n",
        "p3_measurement.extend([eq_nervous_meas,eq_depress_meas,eq_angry_meas])\n",
        "\n",
        "p1_Qnames.extend([\"nervous_calm_1\",\"depressed_cheerful_1\",\"angry_gentle_1\"])\n",
        "p2_Qnames.extend([\"nervous_calm_2\",\"depressed_cheerful_2\",\"angry_gentle_2\"])\n",
        "p3_Qnames.extend([\"nervous_calm_3\",\"depressed_cheerful_3\",\"angry_gentle_3\"])\n",
        "\n",
        "## Appraisal Questions\n",
        "### Same across two types. \n",
        "### P1 includes change, control, valence, famility\n",
        "### P2 includes change, control, valence\n",
        "### P3 includes valence.\n",
        "### All questions have the same likert scale\n",
        "\n",
        "appraisal_likert = r\"\"\"\n",
        "  0 very small\n",
        "  1 fairly small\n",
        "  2 small\n",
        "  3 large\n",
        "  4 fairly large\n",
        "  5 very large\n",
        "\"\"\"\n",
        "## Q4 - 7\n",
        "changeability  = r\"\"\"Q. My judgemnts about this situation are as follows: the chances of this situation taking a turn for the better without effort on my part are\"\"\" \n",
        "controlability = r\"\"\"Q. My judgemnts about this situation are as follows: the chances that I can influence this situation for the better are\"\"\" \n",
        "valence        = r\"\"\"Q. My judgemnts about this situation are as follows: the overall amount of stress for me in this situation is\"\"\" \n",
        "familiarity       = r\"\"\"Q. My judgemnts about this situation are as follows: I have experienced a similar situation\"\"\" \n",
        "\n",
        "p1_aversive.extend([changeability, controlability, valence, familiarity])\n",
        "p2_aversive.extend([changeability, controlability, valence])\n",
        "p3_aversive.extend([valence])\n",
        "p1_lossfailure.extend([changeability, controlability, valence, familiarity])\n",
        "p2_lossfailure.extend([changeability, controlability, valence])\n",
        "p3_lossfailure.extend([valence])\n",
        "\n",
        "p1_measurement.extend([appraisal_likert]*4)\n",
        "p2_measurement.extend([appraisal_likert]*3)\n",
        "p3_measurement.extend([appraisal_likert]*1)\n",
        "\n",
        "p1_Qnames.extend([\"changeability_1\",\"controlability_1\",\"valence_1\",\"familiarity_1\"])\n",
        "p2_Qnames.extend([\"changeability_2\",\"controlability_2\",\"valence_2\"])\n",
        "p3_Qnames.extend([\"valence_3\"])\n",
        "\n",
        "## Coping Goals and Intentions Questions\n",
        "### Slightly difference between Aversive and Lose&Failure\n",
        "### Phase 3 doesn't have Coping goals and intentions (since it's already done.)\n",
        "### Important likery scale\n",
        "\n",
        "important_scale = r\"\"\" \n",
        "  0 not important at all\n",
        "  1 not very important\n",
        "  2 quite important\n",
        "  3 very important\n",
        "\"\"\"\n",
        "## Q8 - 13\n",
        "allo_problem_aver = r\"\"\"Q. In this situation my intention is to actively confront the other(s) and to clear up what is at stake\"\"\" \n",
        " \n",
        "auto_problem_aver = r\"\"\"Q. In this situation, my intention is to maintain a friendly atmosphere and to prevent an argument with the other(s)\"\"\" \n",
        "\n",
        "allo_problem_loss = r\"\"\"Q. In this situation, my intention is to maintain the relationship (or objective) which is at stake\"\"\" \n",
        "\n",
        "auto_problem_loss = r\"\"\"Q. In this situation, my intention is to find alternative relationships (or objectives)\"\"\" \n",
        "\n",
        "emo_ef =  r\"\"\"Q. In this situation, my intention is to remain calm and composed\"\"\" \n",
        "\n",
        "self_esteem_ef = r\"\"\"Q. In this situation, my intention is to keep my self-esteem\"\"\" \n",
        "\n",
        "p1_aversive.extend([allo_problem_aver, auto_problem_aver, emo_ef, self_esteem_ef])\n",
        "p2_aversive.extend([allo_problem_aver, auto_problem_aver, emo_ef, self_esteem_ef])\n",
        "p1_lossfailure.extend([allo_problem_loss, auto_problem_loss, emo_ef, self_esteem_ef])\n",
        "p2_lossfailure.extend([allo_problem_loss, auto_problem_loss, emo_ef, self_esteem_ef])\n",
        "\n",
        "p1_measurement.extend([important_scale]*4)\n",
        "p2_measurement.extend([important_scale]*4)\n",
        "\n",
        "p1_Qnames.extend([\"allo_problem_1\",\"auto_problem_1\",\"emotion_focused_ef_1\",\"self_esteem_ef_1\"])\n",
        "p2_Qnames.extend([\"allo_problem_2\",\"auto_problem_2\",\"emotion_focused_ef_2\",\"self_esteem_ef_2\"])\n",
        "\n",
        "## Attribution of the outcome \n",
        "### Only for the phase 3\n",
        "### Same for both types\n",
        "\n",
        "attribute_scale = r\"\"\" \n",
        "  0 not at all\n",
        "  1 partially \n",
        "  2 mostly \n",
        "  3 entirely\n",
        "\"\"\"\n",
        "### Q29 - 31\n",
        "self_attribute = r\"\"\"Q. I would attribute the outcome of this situation to my own behavior\"\"\" \n",
        "others_attribute = r\"\"\"Q. I would attribute the outcome of this situation to the behavior of the other(s)\"\"\" \n",
        "circumstances_attribute = r\"\"\"Q .I would attribute the outcome of this situation to circumstances\"\"\"\n",
        "\n",
        "p3_aversive.extend([self_attribute, others_attribute, circumstances_attribute])\n",
        "p3_lossfailure.extend([self_attribute, others_attribute, circumstances_attribute])\n",
        "\n",
        "p3_measurement.extend([attribute_scale]*3)\n",
        "\n",
        "p3_Qnames.extend([\"self_attribute_3\",\"others_attribute_3\",\"circumstances_attribute_3\"])\n",
        "\n",
        "## Self-directed Actions/Coping \n",
        "### Same for both types\n",
        "### Slightly difference for phase 3. \n",
        "### Scale is probability that you would do the action\n",
        "\n",
        "prob_scale = r\"\"\"\n",
        "  0 not at all (0%)\n",
        "  1 hardly (25%)\n",
        "  2 perhaps (50%)\n",
        "  3 probably (75%)\n",
        "  4 certainly (100%)\n",
        "\"\"\"\n",
        "### Q14 - Q19\n",
        "\n",
        "act_suppressed_info = r\"\"\"Q. In this situation, I would fade out, stop paying attention or look for distractions\"\"\" \n",
        "act_suppressed_info3 =  r\"\"\"Q. In this situation, I would distance myself from what happened, stop paying attention or look for distractions\"\"\" \n",
        "\n",
        "## (Not quite search for info but this is what Perrez used.)\n",
        "act_search_info = r\"\"\"Q. In this situation, I would make clear to myself what is at stake and what I should do\"\"\" \n",
        "act_search_info3 = r\"\"\"Q. In this situation, I would make clear to myself what was at stake and what I could have done better\"\"\" \n",
        "\n",
        "act_reevaluation = r\"\"\"Q. In this situation, I would make clear to myself that this situation is not as straining/important as other problems\"\"\" \n",
        "\n",
        "act_palliation = r\"\"\"Q. In this situation, I would get my emotions under control (be positive, relax, take a drink, a cigarette, etc.)\"\"\" \n",
        "\n",
        "p1_aversive.extend([act_suppressed_info,act_search_info,act_reevaluation,act_palliation])\n",
        "p2_aversive.extend([act_suppressed_info,act_search_info,act_reevaluation,act_palliation])\n",
        "p3_aversive.extend([act_suppressed_info3,act_search_info3,act_reevaluation,act_palliation])\n",
        "p1_lossfailure.extend([act_suppressed_info,act_search_info,act_reevaluation,act_palliation])\n",
        "p2_lossfailure.extend([act_suppressed_info,act_search_info,act_reevaluation,act_palliation])\n",
        "p3_lossfailure.extend([act_suppressed_info3,act_search_info3,act_reevaluation,act_palliation])\n",
        "\n",
        "p1_measurement.extend([prob_scale]*4)\n",
        "p2_measurement.extend([prob_scale]*4)\n",
        "p3_measurement.extend([prob_scale]*4)\n",
        "\n",
        "p1_Qnames.extend([\"act_suppressed_info_1\",\"act_search_info_1\",\"act_reevaluation_1\",\"act_palliation_1\"])\n",
        "p2_Qnames.extend([\"act_suppressed_info_2\",\"act_search_info_2\",\"act_reevaluation_2\",\"act_palliation_2\"])\n",
        "p3_Qnames.extend([\"act_suppressed_info3_3\",\"act_search_info3_3\",\"act_reevaluation_3\",\"act_palliation_3\"])\n",
        "\n",
        "## Separated out into two batches here so that no batch has more than 5 questions \n",
        "act_blame_other = r\"\"\"Q. In this situation, I would blame or reproach the other(s) or circumstances by myself\"\"\"\n",
        "act_blame_self = r\"\"\"Q. In this situation, I would blame or reproach myself\"\"\" \n",
        "\n",
        "p1_aversive.extend([act_blame_other,act_blame_self])\n",
        "p2_aversive.extend([act_blame_other,act_blame_self])\n",
        "p1_lossfailure.extend([act_blame_other,act_blame_self])\n",
        "p2_lossfailure.extend([act_blame_other,act_blame_self])\n",
        "\n",
        "p1_measurement.extend([prob_scale]*2)\n",
        "p2_measurement.extend([prob_scale]*2)\n",
        "\n",
        "p1_Qnames.extend([\"act_blame_other_1\",\"act_blame_self_1\"])\n",
        "p2_Qnames.extend([\"act_blame_other_2\",\"act_blame_self_2\"])\n",
        "\n",
        "## Environment-directed coping\n",
        "### Two types are different.\n",
        "### Phase 3 is different but Perrez didn't look at them so we skip them.\n",
        "\n",
        "### Q23, Q24, Q25\n",
        "env_passive_aversive = r\"\"\"Q. In this situation, I would behave passively or wait for something to happen\"\"\" \n",
        "env_evasive_aversive = r\"\"\"Q. In this situation, I would try to withdraw from the situation (e.g., by avoiding certain things/people or turning away)\"\"\" \n",
        "env_active_aversive = r\"\"\"Q. In this situation, I would try to actively influence the situation (e.g., by questioning, asking for clarification)\"\"\" \n",
        "\n",
        "### Q26, Q27, Q28\n",
        "env_passive_loss = r\"\"\"Q. In this situation, I would behave passively or wait for something to happen\"\"\" \n",
        "env_active_prevent_loss = r\"\"\"Q. In this situation, I would try to actively prevent a loss or a failure\"\"\" \n",
        "env_active_reorientate_loss = r\"\"\"Q. In this situation, I would try to actively re-orientate my position (e.g., by focusing on other relationships, things, projects)\"\"\" \n",
        "\n",
        "p1_aversive.extend([env_passive_aversive, env_evasive_aversive, env_active_aversive])\n",
        "p2_aversive.extend([env_passive_aversive, env_evasive_aversive, env_active_aversive])\n",
        "p1_lossfailure.extend([env_passive_loss, env_active_prevent_loss, env_active_reorientate_loss])\n",
        "p2_lossfailure.extend([env_passive_loss, env_active_prevent_loss, env_active_reorientate_loss])\n",
        "\n",
        "p1_measurement.extend([prob_scale]*3)\n",
        "p2_measurement.extend([prob_scale]*3)\n",
        "\n",
        "p1_Qnames.extend([\"env_passive_1\",\"env_evasive_1\",\"env_active_1\"])\n",
        "p2_Qnames.extend([\"env_passive_2\",\"env_evasive_2\",\"env_active_2\"])\n",
        "\n",
        "#env_p3_active1 = r\"\"\"Q20. In this situation, I would say to myself, all that, I did quite well\"\"\" + prob_scale\n",
        "#env_p3_active_reorientate = r\"\"\"Q21. In this situation, I would talk to an initimate friend or another person about it\"\"\" + prob_scale\n",
        "#env_p3_active_prevent = r\"\"\"Q22. In this situation, I would intend to make it different next time\"\"\" + prob_scale\n",
        "\n",
        "aversive_questions = [p1_aversive, p2_aversive, p3_aversive]\n",
        "lossfailure_questions = [p1_lossfailure, p2_lossfailure, p3_lossfailure]\n",
        "measurements = [p1_measurement, p2_measurement, p3_measurement]\n",
        "question_names = [*p1_Qnames, *p2_Qnames, *p3_Qnames]\n",
        "p1_batch = [3, 4, 4, 4, 2, 3]\n",
        "p2_batch = [3, 3, 4, 4, 2, 3]\n",
        "p3_batch = [3, 1, 3, 4]\n",
        "batches = [p1_batch, p2_batch, p3_batch]\n",
        "appraisal_questions = [[3, 4, 5], [3, 4, 5], [3]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1nlTvs9W4gZ"
      },
      "source": [
        "#Genearating Results for Perrez stories\n",
        "- Perroz's Hypothesis: \n",
        "  - 1) Effects of situation and process characteristics on subjective appraisals and on emotional reactions of a stressful episode: \n",
        "    - 1.1) According to the objectives of the construction, subjects should perceive **higher controllability and changeability** in the aversive episdoes than in the loss or failure episodes \n",
        "    - 1.2) In both types of stressful situations **controllability and changeability should be perceived as lower over the course of the episodes**, from phase 1 to phase 2, due to the stressor remaining unchanged over time.\n",
        "    - 1.3) Negative valence should be similarly perceived in the two subtests (aver vs loss), but should be in the course of the (unchanged) stressful episdoes. There should be a** strong difference between positive and negative outcome** as described in the hypothetical end of the episode (phase 3)\n",
        "    - 1.4) Concerning the theme or content of the two classes of stressful episdoes, it is to be supposed that aversive stimuluation **by social agents (as presented in some episodes) produces more aggresive and less depressed emotions** than the looming loss or failure events.\n",
        "  - 2) Effects of situation and process on situation-directed behaviors:\n",
        "    - 2.1) **The less controllable** the situations (gross and net control),** the less active influence** on the stressor will be exerted by the subject and,\n",
        "    - 2.2) **the more passivity** (hesitation and resignation) will occur.\n",
        "  - 3) Effects on representation-directed coping efforts: **The lower the ambiguity** of the stressful situation then\n",
        "    - 3.1) **the more limited the serach for information**, and\n",
        "    - 3.2) **the more the subject will surppress information** about the stressor. \n",
        "  - 4) Evaluation-directed coping efforts: **The less controllable** the situation, \n",
        "    - 4.1) **The more the instrumental goals (of influence, substituation) are changed from more alloplastic to more autoplastic adaptation**, especially when stressful effects are long-lasting; because social aversive stressors as convceived in the SCPQ episodes probably represent a stronger attack on the self-esteem of the subject, his or her coping intentions should focus more on the goal of (re)equilibration of self-esteem;\n",
        "    - 4.2) **the more re-evaluation is increased to change the relavance or valence of the actual situation.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9XToefv-W7N1"
      },
      "outputs": [],
      "source": [
        "## Query all Pereze Stories \n",
        "wait_time = 3\n",
        "\n",
        "## After version\n",
        "instruction_choice = r\"\"\"Try to clearly imagine the above situation and then answer the question with the choice only in one line.\n",
        "\"\"\"\n",
        "instruction_num = r\"\"\"Try to clearly imagine the above situation and then answer the question with the choice's number only in one line.\n",
        "\"\"\"\n",
        "instruction_depressed = r\"\"\"I want you to act as a person with depression. Try to clearly imagine the above situation and then answer the question with the choice only in one line.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "instructions = [instruction_choice, instruction_num, instruction_depressed]\n",
        "\n",
        "batch_instruction_choice = r\"\"\"Try to clearly imagine the above situation and then answer all the following question(s) with the choice only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instruction_num = r\"\"\"Try to clearly imagine the above situation and then answer all the following question(s) with the choice's number only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instruction_depressed = r\"\"\"I want you to act as a person with depression. Try to clearly imagine the above situation and then answer all the following question(s) with the choice's number only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instructions = [batch_instruction_choice, batch_instruction_num, batch_instruction_depressed]\n",
        "\n",
        "## Before version\n",
        "instruction_bef_choice = r\"\"\"Try to clearly imagine the situation below and then answer the question with the choice only in one line.\n",
        "\"\"\"\n",
        "instruction_bef_num = r\"\"\"Try to clearly imagine the situation below and then answer the question with the choice's number only in one line.\n",
        "\"\"\"\n",
        "instruction_bef_depressed = r\"\"\"I want you to act as a person with depression. Try to clearly imagine the situation below and then answer the question with the choice only in one line.\n",
        "\"\"\"\n",
        "\n",
        "instructions_bef = [instruction_bef_choice, instruction_bef_num, instruction_bef_depressed]\n",
        "\n",
        "batch_instruction_bef_choice = r\"\"\"Try to clearly imagine the situation below and then answer all the following question(s) with the choice only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instruction_bef_num = r\"\"\"Try to clearly imagine the situation below and then answer all the following question(s) with the choice's number only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instruction_bef_depressed = r\"\"\"I want you to act as a person with depression. Try to clearly imagine the situation below and then answer all the following question(s) with the choice's number only in one line separated by a comma (e.g., \"1, 2, 3\").\n",
        "\"\"\"\n",
        "batch_instructions_bef = [batch_instruction_bef_choice, batch_instruction_bef_num, batch_instruction_bef_depressed]\n",
        "\n",
        "def getAppraisalAnswers(answer):\n",
        "  appraisal_answers = ['very small','fairly small','fairly large','very large','small','large'] ##Small and large have to be last.\n",
        "  for ans in appraisal_answers:\n",
        "    if answer.find(ans) != -1:\n",
        "      return ans\n",
        "  print(\"NO ANSWER\")\n",
        "  return \"no answer.\"\n",
        "\n",
        "## Generate the responses from openAI API for one Perrez story\n",
        "## model = [\"text-davinci-003\",\"gpt-3.5-turbo-0301\"]\n",
        "## mode: 1) individual = asking one question at at time.\n",
        "##       2) batch = asking a batch of the same kind of questions \n",
        "## history: append the full history or not. \n",
        "def getResponsedPerrezStory(story, type, model, instruction=0, instruct_before = False, history=False, mode=\"individual\", \n",
        "                            temperature=0, echo=False):\n",
        "  out = []\n",
        "  temp_story = \"\"\n",
        "  for i in range(3): \n",
        "    temp_story += \" \" + story[i] ## This will add one empty space before the story. should not be a problem.\n",
        "    questions = aversive_questions if type == \"aversive\" else lossfailure_questions\n",
        "    if mode == \"individual\":\n",
        "      for j in range(len(questions[i])):\n",
        "        prompt = temp_story + \"\\n\" + instructions[instruction]  + questions[i][j] + measurements[i][j] \n",
        "        if instruct_before: \n",
        "          prompt =  instructions_bef[instruction] + temp_story + \"\\n\"  + questions[i][j] + measurements[i][j]\n",
        "        response = gptQuery(prompt = prompt, model=model, temperature=temperature)\n",
        "        \n",
        "        time.sleep(wait_time) ## Need to wait to not go over api rate limit\n",
        "        out.extend(response) ## store the response\n",
        "        if echo:\n",
        "          print(prompt)\n",
        "          print(response)\n",
        "        if history and (j in appraisal_questions[i]): \n",
        "          ## Only append appraisal questions \n",
        "          temp_story += \"\\n\" + questions[i][j][3:] + \" \" + getAppraisalAnswers(response[0]) + \".\" \n",
        "      if history: temp_story +=\"\\n\" ##Add a new line for the history version since the early parts are followed by appraisal answers\n",
        "    if mode == \"batch\":\n",
        "      ind = 0\n",
        "      for j in range(len(batches[i])):\n",
        "        temp_questions = \"\"\n",
        "        ## Gather questions\n",
        "        for k in range(batches[i][j]):\n",
        "          temp_questions += questions[i][ind] + measurements[i][ind]\n",
        "          ind += 1\n",
        "        prompt = temp_story + \"\\n\" + batch_instructions[instruction]  + temp_questions \n",
        "        if instruct_before: \n",
        "          prompt =  batch_instructions_bef[instruction] + temp_story + \"\\n\"  + temp_questions \n",
        "        response = gptQuery(prompt = prompt, model = model, temperature=temperature)\n",
        "        \n",
        "        time.sleep(wait_time) ## Need to wait to not go over api rate limit\n",
        "        out.extend(response)\n",
        "        if echo:\n",
        "          print(prompt)\n",
        "          print(response)\n",
        "\n",
        "  return out\n",
        "\n",
        "## Cleaning up answers\n",
        "def findFirstNumber(txt):\n",
        "  nums = [int(s) for s in txt if s.isdigit()]\n",
        "  if len(nums) == 0:\n",
        "    return\n",
        "  return nums[0]\n",
        "\n",
        "## split the response by comma and the gap the first n numbers where n is the number of questions\n",
        "def postProcessPerrezResponses(responses, batch = []):\n",
        "  out = []\n",
        "  for i in range(len(responses)): \n",
        "    temp = [findFirstNumber(s) for s in responses[i].split(',')]\n",
        "    if None in temp: temp.remove(None) ##This would remove comma split without numbers\n",
        "    while len(temp) < batch[i]: temp.append(None)\n",
        "    out.extend(temp[0:batch[i]])\n",
        "  return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iI-jift93eBV"
      },
      "outputs": [],
      "source": [
        "individual_n = [1]*len(question_names) \n",
        "batches_n    = [*p1_batch, *p2_batch, *p3_batch]\n",
        "\n",
        "def genAllPerrezStory(model, mode, instruction=0, instruct_before=False, history = False, temperature=0, n=0, echo = False):\n",
        "  results = []\n",
        "  temp_n = individual_n  if mode == \"individual\" else batches_n\n",
        "  for i in range(len(perrez_stories)):\n",
        "    print(i)\n",
        "    print(f'{perrez_stories[i]}')\n",
        "    temp = getResponsedPerrezStory(perrez_stories[i], types[i], mode=mode, \n",
        "                                 model=model, instruction=instruction, instruct_before = instruct_before,\n",
        "                                 history=history, temperature = temperature, echo=echo)\n",
        "    print(temp)\n",
        "    temp = postProcessPerrezResponses(temp, batch=temp_n)\n",
        "    print(temp)\n",
        "    print(len(temp))\n",
        "    results.append(temp)\n",
        "\n",
        "  # Saving the output\n",
        "  df = pd.DataFrame(results, columns = question_names)\n",
        "  file_name = \"Results_\" + model + \"_\" + mode + \"_Temp=\" + str(temperature) + \"_n=\" + str(n) + \"_instruction=\" + str(instruction) + \"_instruct_bef=\" + str(instruct_before) + \"_hist=\" + str(history) + \".csv\"\n",
        "  df.to_csv(file_name)\n",
        "\n",
        "## Don't use anymore\n",
        "def genOnePerrezStory(story_ind, model, mode, instruction=0, instruct_before=False, temperature=0, n=0, echo=False):\n",
        "  results = []\n",
        "  temp_n = individual_n  if mode == \"individual\" else batches_n\n",
        "  print(f'{perrez_stories[story_ind]}')\n",
        "  temp = getResponsedPerrezStory(perrez_stories[story_ind], types[story_ind], mode=mode, \n",
        "                                 model=model, instruction=instruction, instruct_before = instruct_before, temperature = temperature, echo=echo)\n",
        "  print(temp)\n",
        "  temp = postProcessPerrezResponses(temp, batch=temp_n)\n",
        "  print(temp)\n",
        "  print(len(temp))\n",
        "  results.append(temp)\n",
        "\n",
        "  # Saving the output\n",
        "  df = pd.DataFrame(results, columns = question_names)\n",
        "  file_name = \"Results_\" + model + \"_story=\" + str(story_ind) + \"_\" + mode + \"_Temp=\" + str(temperature) + \"_n=\" + str(n) + \"_instruction=\" + str(instruction) + \"_instruct_bef=\" + str(instruct_before) + \".csv\"\n",
        "  df.to_csv(file_name)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "93dPfw4-9YUW"
      },
      "source": [
        "# Setup \n",
        "- 3 x models: 3.5, chat, 4\n",
        "- 2 x modes of questions: Individual or Batch \n",
        "- 4 Instructions\n",
        "- Total = 24\n",
        "- Others: 1) Conditioned on early questions and answers within phase \n",
        "- Personality/Depressed\n",
        "\n",
        "Warning: There are 50 questions per story and there are 18 stories so that would be a total of 900 queries. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Individual Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Bl6Wj59JTc_"
      },
      "outputs": [],
      "source": [
        "## Text-davinci-003\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction = 0, instruct_before=False)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction = 1, instruct_before=False)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction = 0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction = 1, instruct_before=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo7S5dvkJVRH"
      },
      "outputs": [],
      "source": [
        "## GPT3.5-turbo (ChatGPT)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"individual\", instruction = 0, instruct_before=False)\n",
        "\n",
        "genAllPerrezStory(model=models[1], mode = \"individual\", instruction = 1, instruct_before=False)\n",
        "\n",
        "## Asking to answer with \"Choice\" can cause Chatgpt to repeat the question or give an answer that just refers to the story.\n",
        "# genAllPerrezStory(model=models[1], mode = \"individual\", instruction = 0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"individual\", instruction = 1, instruct_before=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5_xTig8JW2n"
      },
      "outputs": [],
      "source": [
        "## GTP4\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction = 0, instruct_before=False)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction = 1, instruct_before=False)\n",
        "\n",
        "## Got one \"I cannot answer this question as I am an AI language model and cannot have personal experiences or judgments.\"\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction = 0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction = 1, instruct_before=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inSOeE5z6SuV"
      },
      "outputs": [],
      "source": [
        "## Text-davinci-003\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"batch\", instruction=0)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"batch\", instruction=1)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"batch\", instruction=0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"batch\", instruction=1, instruct_before=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdjrgPHkJO__"
      },
      "outputs": [],
      "source": [
        "## GPT3.5-turbo (ChatGPT)\n",
        "### For chatGpt (instruction = 0), a few times (story 2, 12, 15, 18) it didn't answer a few questions (mainly palliation) <- fill with mode\n",
        "### and also not answer with just numbers for a few blame yourself/other question in p1. \n",
        "\n",
        "### For chatGpt (instruction = 1), a few times (story 1, 11, 13, 15, 18), it didn't answer a few questions (again palliation) \n",
        "### and also not answer wih just numbers for a few blame self,other, circumstances in p3.\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"batch\", instruction=0)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"batch\", instruction=1)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"batch\", instruction=0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"batch\", instruction=1, instruct_before=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJSy9WQ8JSKh"
      },
      "outputs": [],
      "source": [
        "## GPT-4\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"batch\", instruction=0)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"batch\", instruction=1)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"batch\", instruction=0, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"batch\", instruction=1, instruct_before=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conditioned on appraisal answers version\n",
        "- Only test with instruction with word choices and individual mode \n",
        "- Because answering with questions or batch answering doesn't make much sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Only individual\n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction=0, instruct_before=True, history = True)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"individual\", instruction=0, instruct_before=True, history = True)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction=0, instruct_before=True, history = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Act as a person with depression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Just Individual \n",
        "\n",
        "# genAllPerrezStory(model=models[0], mode = \"individual\", instruction=2, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[1], mode = \"individual\", instruction=2, instruct_before=True)\n",
        "\n",
        "# genAllPerrezStory(model=models[2], mode = \"individual\", instruction=2, instruct_before=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Don't need this anymore\n",
        "## Combine individual story into one full dataset and save to the file\n",
        "def mergeInvidual(model, mode, temperature, num, instruction):\n",
        "    out = []\n",
        "    for i in range(18):\n",
        "        file_name = \"Results_\" + model + \"_story=\" + str(story_ind) + \"_\" + mode + \"_Temp=\" + str(temperature) + \"_n=\" + str(num) + \"_instruction=\" + str(instruction) + \".csv\"\n",
        "        out.append(pd.read_csv(file_name))\n",
        "    file_name = \"Results_\" + model + \"_\" + mode + \"_Temp=\" + str(temperature) + \"_n=\" + str(num) + \"_instruction=\" + str(instruction) + \".csv\"\n",
        "    df = pd.concat(out)\n",
        "    df.to_csv(file_name)\n",
        "    return(df)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb5ff6be2c42e38762b2676856d251fe1a5f073827e1195963cd8267f1d4f4d0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
